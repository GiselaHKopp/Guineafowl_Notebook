[["index.html", "Guineafowl-lcWGS Notebook Project Notebook 1 Intro 1.1 Dependencies", " Guineafowl-lcWGS Notebook Project Notebook Gisela H. Kopp 2021-07-20 1 Intro Hello, this is a minimal {bookdown} diary-style notebook to document this project. The documentation of this project is broken down into several chunks: 1 Intro: General intro to the project (you are looking at this right now) 2 Project development: Here I keep a diary of the development of the project. 3 Notes: Notes on ideas, what should be or has been read, etc. 4 Data: The data needed and compiled for the project. 5 Analysis: The analysis. (We might want to break this into several subsections) 6 References: This is where session infor and all cited sources of your project will be listed. 1.1 Dependencies To be able to use this in your own projects you will need to R as well as the {bookdown} package installed: install.packages(&quot;bookdown&quot;) Feel free to adapt this template to your needs. "],["project-development.html", "2 Project development 2.1 General idea", " 2 Project development Here I track and document the development of the project in a diary style. 2.1 General idea The general idea for this project is "],["project-notes.html", "3 Project notes 3.1 Reading (notes) 3.2 Ideas to follow up on", " 3 Project notes Here I note ideas and papers read or must read. 3.1 Reading (notes) 3.2 Ideas to follow up on "],["data.html", "4 Data 4.1 Setup 4.2 Data collection 4.3 Data processing", " 4 Data Data compiled and used in this project 4.1 Setup library(tidyverse) #&gt; -- Attaching packages ------------------------------------------------------------------------------------------------------------------ tidyverse 1.3.0 -- #&gt; v ggplot2 3.3.2 v purrr 0.3.4 #&gt; v tibble 3.0.3 v dplyr 1.0.2 #&gt; v tidyr 1.1.2 v stringr 1.4.0 #&gt; v readr 1.3.1 v forcats 0.5.0 #&gt; -- Conflicts --------------------------------------------------------------------------------------------------------------------- tidyverse_conflicts() -- #&gt; x dplyr::filter() masks stats::filter() #&gt; x dplyr::lag() masks stats::lag() library(ggplot2) library(ggthemes) library(ggforce) library(ggridges) library(ggsci) library(wesanderson) library(ggallin) 4.2 Data collection Group information is stored in sequenced_samples_groups.csv. sampleID_group &lt;- read.csv(&quot;vignettes/data/sequenced_samples_groups.csv&quot;, header = TRUE, sep = &quot;;&quot;, as.is = TRUE) str(sampleID_group) #&gt; &#39;data.frame&#39;: 95 obs. of 4 variables: #&gt; $ Group_ID : chr &quot;wing_tags&quot; &quot;wing_tags&quot; &quot;wing_tags&quot; &quot;wing_tags&quot; ... #&gt; $ Sample.ind.code: chr &quot;A1295&quot; &quot;A1296&quot; &quot;A1297&quot; &quot;A1298&quot; ... #&gt; $ Real.ind.code : chr &quot;W1295&quot; &quot;W1296&quot; &quot;W1297&quot; &quot;W1298&quot; ... #&gt; $ Colour_.bands : chr &quot;WT002&quot; &quot;WT003&quot; &quot;WT004&quot; &quot;WT021&quot; ... #rename Real.ind.code to ID sampleID_group &lt;- rename(sampleID_group, &quot;ID&quot; = &quot;Sample.ind.code&quot;) #only keep group and ID sampleID_group &lt;- select(sampleID_group, Group_ID, ID) str(sampleID_group) #&gt; &#39;data.frame&#39;: 95 obs. of 2 variables: #&gt; $ Group_ID: chr &quot;wing_tags&quot; &quot;wing_tags&quot; &quot;wing_tags&quot; &quot;wing_tags&quot; ... #&gt; $ ID : chr &quot;A1295&quot; &quot;A1296&quot; &quot;A1297&quot; &quot;A1298&quot; ... 4.3 Data processing 4.3.1 Sequencing data First we evaluate the quality of the data and the different sequencing approaches. An overview of the data as of 26th April 2021 is stored in Guineafowl-lcWGS_DataOverview_20210426.csv data_overview &lt;- read.csv(&quot;vignettes/data/Guineafowl-lcWGS_DataOverview_20210426.csv&quot;, header = TRUE, sep = &quot;;&quot;, as.is = TRUE) str(data_overview) #&gt; &#39;data.frame&#39;: 119 obs. of 17 variables: #&gt; $ individual : chr &quot;W1398&quot; &quot;W1429&quot; &quot;W1429&quot; &quot;W1502&quot; ... #&gt; $ library : chr &quot;L16926&quot; &quot;L16927&quot; &quot;L16927&quot; &quot;L16928&quot; ... #&gt; $ run : chr &quot;S2&quot; &quot;S1&quot; &quot;S3&quot; &quot;S4&quot; ... #&gt; $ original.o..resequenced.r. : chr &quot;o&quot; &quot;r&quot; &quot;o&quot; &quot;o&quot; ... #&gt; $ readGroupID : int 4 5 4 4 4 5 4 4 4 4 ... #&gt; $ total.reads : int 6720264 21332072 6069840 13390576 12081324 11995744 5684766 7759668 12174890 11373232 ... #&gt; $ trim.input.reads : int 3360132 10666036 3034920 6695288 6040662 5997872 2842383 3879834 6087445 5686616 ... #&gt; $ trim.reads.survived.both : int 2544284 9427764 2360036 5279275 4602830 5309238 2225803 2852960 4754568 4400910 ... #&gt; $ trim.reads.dropped.... : num 0.24 0.12 0.22 0.21 0.24 0.11 0.22 0.26 0.22 0.23 ... #&gt; $ mapped.reads : int 4987783 18494700 4631339 10376967 9021788 10412331 4367512 5598370 9342782 8636957 ... #&gt; $ mapped.reads.... : num 98 98.1 98.1 98.3 98 ... #&gt; $ coverage.mean : num 0.56 2.06 0.52 1.14 0.97 1.14 0.48 0.63 1.05 0.98 ... #&gt; $ coverage.st.dev. : num 2.48 4.96 2.58 2.8 3.81 3.56 2.18 2.43 2.58 3.13 ... #&gt; $ Duplicates.... : num 5.07 8.13 4.92 5.2 5.09 9.35 5.56 4.54 4.59 4.84 ... #&gt; $ Lib.complexity.total.reads : int 2250000 8750000 2250000 5000000 4250000 4750000 2000000 2750000 4500000 4250000 ... #&gt; $ Lib.complexity.distinct.reads: int 2224740 8608220 2221360 4963340 4181270 4688400 1979850 2722780 4466910 4203570 ... #&gt; $ number.of.snps : logi NA NA NA NA NA NA ... save data overview save(data_overview, file = &quot;data_overview.RData&quot;) Calculate total and mean number of raw reads !!paired-end sequencing, so need to account for that total_raw_reads &lt;- sum(data_overview$total.reads) total_raw_reads #&gt; [1] 1393934732 mean_raw_reads &lt;- mean(data_overview$total.reads) mean_raw_reads #&gt; [1] 11713737 sd_raw_reads &lt;- sd(data_overview$total.reads) sd_raw_reads #&gt; [1] 5979400 Calculate total and mean number of quality filtered reads total_filtered_reads &lt;- sum(data_overview$trim.reads.survived.both) total_filtered_reads #&gt; [1] 558670307 percent_filtered_reads &lt;- total_filtered_reads/(0.5*total_raw_reads) #account for paired reads by percent_filtered_reads #&gt; [1] 0.8015731 mean_filtered_reads &lt;- mean(data_overview$trim.reads.survived.both) mean_filtered_reads #&gt; [1] 4694708 percent_mean_filtered_reads &lt;- mean_filtered_reads/(0.5*mean_raw_reads) percent_mean_filtered_reads #&gt; [1] 0.8015731 sd_filtered_reads &lt;- sd(data_overview$trim.reads.survived.both) sd_filtered_reads #&gt; [1] 2573996 median_Trimmomatic_dropped &lt;- median(data_overview$trim.reads.dropped...., na.rm = TRUE) median_Trimmomatic_dropped #&gt; [1] 0.22 IQR_Trimmomatic_dropped &lt;- IQR(data_overview$trim.reads.dropped...., na.rm = TRUE) IQR_Trimmomatic_dropped #&gt; [1] 0.035 range_Trimmomatic_dropped &lt;- range(data_overview$trim.reads.dropped...., na.rm = TRUE) range_Trimmomatic_dropped #&gt; [1] 0.10 0.31 Calculate mapped reads median_mapped_reads &lt;- median(data_overview$mapped.reads, na.rm = TRUE) median_mapped_reads #&gt; [1] 8102554 IQR_mapped_reads &lt;- IQR(data_overview$mapped.reads, na.rm = TRUE) IQR_mapped_reads #&gt; [1] 5980470 range_mapped_reads &lt;- range(data_overview$mapped.reads, na.rm = TRUE) range_mapped_reads #&gt; [1] 1564428 31252553 Calculate duplicates median_duplicates &lt;- median(data_overview$Duplicates...., na.rm = TRUE) median_duplicates #&gt; [1] 4.92 range_duplicates &lt;- range(data_overview$Duplicates...., na.rm = TRUE) range_duplicates #&gt; [1] 3.39 10.02 Calculate final coverage median_final_coverage &lt;- median(data_overview$coverage.mean, na.rm = TRUE) median_final_coverage #&gt; [1] 0.91 IQR_final_coverage &lt;- IQR(data_overview$coverage.mean, na.rm = TRUE) IQR_final_coverage #&gt; [1] 0.665 range_final_coverage &lt;- range(data_overview$coverage.mean, na.rm = TRUE) range_final_coverage #&gt; [1] 0.17 3.46 For the sequencing success, we compare the reads that passed Quality control (FastCQ and Trimmotaic) depending on original run and resequencing. theme_set(theme_bw()) #set theme to black and white #compare reads (y-axis) between original vs. resequenced (x-axis, sorted to have original first) and color according to library prep (shotgun vs. capture) ggplot(data_overview, aes(x = factor(original.o..resequenced.r., level = c(&quot;o&quot;, &quot;r&quot;)), y = trim.reads.survived.both, color = original.o..resequenced.r., shape = original.o..resequenced.r.)) + # scale_color_manual(values = wes_palette(&quot;Zissou1&quot;, n = 2)) + geom_point(size = 2, alpha = 0.6, aes(group = individual), position = position_dodge(0.5)) + #make points, transparent, and group samples geom_boxplot(alpha = 0.4, outlier.shape = NA) + #add boxplots but do not show them in legend #geom_violin(alpha = 0.5) + #or add violin plots geom_line(aes(group = individual), color = &quot;grey&quot;, position = position_dodge(0.5), show.legend = FALSE) + #add line to connect samples present in both library approaches #stat_summary(fun = median, geom = &quot;point&quot;, size = 5, alpha = 0.3, position = position_dodge(0.5)) + labs(x = &quot;sequencing run&quot;, y = &quot;reads after quality filtering&quot;) + #adjust axis labels theme(legend.title = element_blank()) + #remove legend title theme(panel.grid.major.x = element_blank()) #remove x-axis grid lines Maybe more informative about the success of the approaches is to compare for the different library approaches (shotgun and capture enrichment, respectively), % reads that mapped in BWA. theme_set(theme_bw()) #set theme to black and white #compare mapped reads (y-axis) between sequencing (x-axis, sorted to have original first) and color according to library prep (shotgun vs. capture) ggplot(data_overview, aes(x = factor(original.o..resequenced.r., level = c(&quot;o&quot;, &quot;r&quot;)), y = mapped.reads, color = original.o..resequenced.r., shape = original.o..resequenced.r.)) + # scale_color_manual(values = wes_palette(&quot;Zissou1&quot;, n = 2)) + geom_point(size = 2, alpha = 0.6, aes(group = individual), position = position_dodge(0.5)) + #make points, transparent, and group samples geom_boxplot(alpha = 0.4, outlier.shape = NA) + #add boxplots but do not show them in legend #geom_violin(alpha = 0.5) + #or add violin plots geom_line(aes(group = individual), color = &quot;grey&quot;, position = position_dodge(0.5), show.legend = FALSE) + #add line to connect samples present in both library approaches #stat_summary(fun = median, geom = &quot;point&quot;, size = 5, alpha = 0.3, position = position_dodge(0.5)) + labs(x = &quot;sequencing run&quot;, y = &quot;mapped reads&quot;) + #adjust axis labels theme(legend.title = element_blank()) + #remove legend title theme(panel.grid.major.x = element_blank()) #remove x-axis grid lines Finally, lets have a look at the coverage theme_set(theme_bw()) #set theme to black and white #relate number of reads (y-axis) to final coverage (x-axis), color according to sequencing (shotgun vs. capture) and sample type, shape according to original run or resequencing ggplot(data_overview, aes(x = coverage.mean, y = trim.reads.survived.both, color = original.o..resequenced.r., shape = original.o..resequenced.r.)) + geom_line(aes(group = individual), color = &quot;lightgrey&quot;, show.legend = FALSE) + #connect same samples geom_point(alpha = 0.5, aes(group = individual, size = mapped.reads....)) + #add points with slight transparency geom_vline(xintercept = 1, linetype = &quot;dashed&quot;) + #include vertical line to show coverage cutoff #scale_y_log10(breaks = scales::trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = scales::trans_format(&quot;log10&quot;, scales::math_format(10^.x))) + #make y-axis logarithmic #scale_x_log10() + #make x-axis logarithmic #annotation_logticks() + labs(x = &quot;coverage&quot;, y = &quot;reads (after quality filtering)&quot;, size = &quot;% reads mapped&quot;, color =&quot;&quot;, shape = &quot;&quot;) C-Curve theme_set(theme_bw()) #set theme to black and white #relate number of distinct reads (y-axis) to total reads (x-axis), color and shape according to original run or resequencing ggplot(data_overview, aes(x = Lib.complexity.total.reads, y = Lib.complexity.distinct.reads, color = original.o..resequenced.r., shape = original.o..resequenced.r.)) + #geom_line(aes(group = individual), color = &quot;lightgrey&quot;, show.legend = FALSE) + #connect same samples geom_point(alpha = 0.5, aes(group = individual, size = coverage.mean)) + #add points with slight transparency theme(panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank()) + #remove x/y-axis grid lines labs(x = &quot;total mapped reads&quot;, y = &quot;distinct mapped reads&quot;, size = &quot;coverage&quot;, color =&quot;&quot;, shape = &quot;&quot;) #adjust axis and legend labels #scale_color_manual(values = wes_palette(&quot;Zissou1&quot;, n = 5)) comparison to total surviving reads from Trimmomatic to distinct mapped reads theme_set(theme_bw()) #set theme to black and white #relate number of distinct reads (y-axis) to total surviving reads (x-axis), color and sample type, shape according to original run or resequencing ggplot(data_overview, aes(x = trim.reads.survived.both, y = Lib.complexity.distinct.reads, color = original.o..resequenced.r., shape = original.o..resequenced.r.)) + geom_point(alpha = 0.5, aes(group = individual, size = coverage.mean)) + #add points with slight transparency theme(panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank()) + #remove x/y-axis grid lines labs(x = &quot;total surviving reads (Trimmomatic)&quot;, y = &quot;distinct mapped reads&quot;, size = &quot;coverage&quot;, color =&quot;&quot;, shape = &quot;&quot;) #adjust axis and legend labels plot coverage and st.dv. theme_set(theme_bw()) #set theme to black and white #plot coverage (y-axis) including st.dev for every sample (x-axis), color according to original run or resequencing ggplot(data_overview, aes(x = reorder(individual, coverage.mean), y = coverage.mean, color = original.o..resequenced.r., shape = original.o..resequenced.r.)) + geom_point(aes(y=coverage.mean), alpha = 0.9) + geom_errorbar(aes(ymin = coverage.mean - coverage.st.dev., ymax = coverage.mean + coverage.st.dev.)) + geom_hline(yintercept = 1, linetype = &quot;dashed&quot;) + #include horizontal line to show coverage cutoff labs(x = &quot;sample&quot;, y = &quot;coverage (mean+-sd)&quot;, color =&quot;&quot;, shape = &quot;&quot;) + #adjust axis and legend labels theme(axis.text.x = element_text(angle = 50, vjust = 1, hjust = 1, size = 8)) + scale_x_discrete(guide = guide_axis(n.dodge=2)) #avoid overlap of x-axis labels 4.3.2 Relatedness data First load an overview of the analysed sequencing libraries. They are stored in the folder pipeline as file_list.tsv. seqlib_overview &lt;- read.delim(&quot;vignettes/data/pipeline/file_list.tsv&quot;, header = TRUE, as.is = TRUE) str(seqlib_overview) #&gt; &#39;data.frame&#39;: 238 obs. of 6 variables: #&gt; $ file_name: chr &quot;mpg_L16936-1_W1350_S1_R1_001.fastq.gz&quot; &quot;mpg_L16936-1_W1350_S1_R2_001.fastq.gz&quot; &quot;mpg_L16926-1_W1398_S2_R1_001.fastq.gz&quot; &quot;mpg_L16926-1_W1398_S2_R2_001.fastq.gz&quot; ... #&gt; $ RGID : int 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ RGLB : chr &quot;lib1&quot; &quot;lib1&quot; &quot;lib1&quot; &quot;lib1&quot; ... #&gt; $ RGPL : chr &quot;ILLUMINA&quot; &quot;ILLUMINA&quot; &quot;ILLUMINA&quot; &quot;ILLUMINA&quot; ... #&gt; $ RGPU : chr &quot;unit1&quot; &quot;unit1&quot; &quot;unit1&quot; &quot;unit1&quot; ... #&gt; $ RGSM : chr &quot;RGID1_S1&quot; &quot;RGID1_S1&quot; &quot;RGID1_S2&quot; &quot;RGID1_S2&quot; ... The information about the sampled individual, which we will later need to assign the relatedness estimation to specific individuals, is available in the file_name column. We will extract this information and put it in an extra ID column. #first need to create a new column that includes the sample ID seqlib_overview$ID &lt;- gsub(&quot;([[:alnum:]]{3}_[[:alnum:]]{6}-[[:digit:]])_([[:alnum:]]{5,7})_([[:alnum:]]{2,3}_[[:alnum:]]{2}_[[:graph:]]{12})&quot;, &quot;\\\\2&quot;, seqlib_overview$file_name) str(seqlib_overview) #&gt; &#39;data.frame&#39;: 238 obs. of 7 variables: #&gt; $ file_name: chr &quot;mpg_L16936-1_W1350_S1_R1_001.fastq.gz&quot; &quot;mpg_L16936-1_W1350_S1_R2_001.fastq.gz&quot; &quot;mpg_L16926-1_W1398_S2_R1_001.fastq.gz&quot; &quot;mpg_L16926-1_W1398_S2_R2_001.fastq.gz&quot; ... #&gt; $ RGID : int 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ RGLB : chr &quot;lib1&quot; &quot;lib1&quot; &quot;lib1&quot; &quot;lib1&quot; ... #&gt; $ RGPL : chr &quot;ILLUMINA&quot; &quot;ILLUMINA&quot; &quot;ILLUMINA&quot; &quot;ILLUMINA&quot; ... #&gt; $ RGPU : chr &quot;unit1&quot; &quot;unit1&quot; &quot;unit1&quot; &quot;unit1&quot; ... #&gt; $ RGSM : chr &quot;RGID1_S1&quot; &quot;RGID1_S1&quot; &quot;RGID1_S2&quot; &quot;RGID1_S2&quot; ... #&gt; $ ID : chr &quot;W1350&quot; &quot;W1350&quot; &quot;W1398&quot; &quot;W1398&quot; ... 4.3.2.1 ngsRelate This is an assessment of the ngsRelate results produced by the Nextflow pipleine created by Ben Hume/SeqAna. The data is saved in the folder pipeline in ngsrelate as relatedness.isec.0002.exMito.thinned.ngsrelate.w.sample.names.results. ngsRelate_results &lt;- read.delim(&quot;vignettes/data/pipeline/ngsrelate/relatedness.isec.0002.exMito.thinned.ngsrelate.w.sample.names.results&quot;, header = TRUE, as.is = TRUE) str(ngsRelate_results) #&gt; &#39;data.frame&#39;: 7021 obs. of 35 variables: #&gt; $ a : int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ b : int 1 2 3 4 5 6 7 8 9 10 ... #&gt; $ ida : chr &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; ... #&gt; $ idb : chr &quot;RGID1_S83&quot; &quot;RGID1_S82&quot; &quot;RGID1_S29&quot; &quot;RGID1_S67&quot; ... #&gt; $ nSites : int 233689 234757 221081 143705 199687 175701 234355 233089 217726 201737 ... #&gt; $ J9 : num 0.659 0.753 0.718 0.479 0.793 ... #&gt; $ J8 : num 2.5e-05 0.0 0.0 0.0 0.0 0.0 1.0e-06 0.0 2.0e-06 0.0 ... #&gt; $ J7 : num 0.0895 0.0167 0.0695 0.1231 0.0374 ... #&gt; $ J6 : num 0 0 0 0.301 0 ... #&gt; $ J5 : num 0e+00 0e+00 0e+00 0e+00 0e+00 5e-06 0e+00 0e+00 2e-06 0e+00 ... #&gt; $ J4 : num 0.2516 0.2305 0.1958 0 0.0152 ... #&gt; $ J3 : num 3e-05 0e+00 0e+00 0e+00 0e+00 0e+00 1e-06 0e+00 0e+00 0e+00 ... #&gt; $ J2 : num 0 0 0.0163 0.0972 0.1542 ... #&gt; $ J1 : num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ rab : num 0.0896 0.0167 0.0695 0.1231 0.0374 ... #&gt; $ Fa : num 0.2516 0.2305 0.212 0.0972 0.1694 ... #&gt; $ Fb : num 0 0 0.0163 0.3984 0.1542 ... #&gt; $ theta : num 0.04479 0.00836 0.03476 0.06153 0.01871 ... #&gt; $ inbred_relatedness_1_2: num 1.5e-05 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... #&gt; $ inbred_relatedness_2_1: num 0e+00 0e+00 0e+00 0e+00 0e+00 3e-06 0e+00 0e+00 1e-06 0e+00 ... #&gt; $ fraternity : num 0.0895 0.0167 0.0858 0.2202 0.1917 ... #&gt; $ identity : num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ zygosity : num 0.0895 0.0167 0.0858 0.2203 0.1917 ... #&gt; $ X2of3_IDB : num 0.215 0.132 0.184 0.371 0.199 ... #&gt; $ F_diff_a_b : num 0.1258 0.1152 0.0979 -0.1506 0.0076 ... #&gt; $ loglh : num -365521 -363424 -356154 -230552 -323300 ... #&gt; $ nIter : int 98 70 50 49 106 126 58 106 46 74 ... #&gt; $ bestoptimll : int -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ... #&gt; $ coverage : num 0.769 0.773 0.728 0.473 0.657 ... #&gt; $ X2dsfs : chr &quot;3.039179e-01,2.036214e-01,2.094838e-02,6.661272e-02,1.854916e-01,1.848313e-02,3.551968e-02,1.058010e-01,5.960424e-02&quot; &quot;2.875679e-01,2.230266e-01,1.833730e-02,7.125856e-02,1.806006e-01,1.774522e-02,3.736186e-02,1.129873e-01,5.111459e-02&quot; &quot;3.254700e-01,1.557393e-01,4.307152e-02,8.846841e-02,1.586388e-01,3.064090e-02,5.576987e-02,7.216507e-02,7.003613e-02&quot; &quot;3.661364e-01,5.993366e-02,6.546616e-02,1.391685e-01,1.241034e-01,7.057984e-02,5.589929e-02,2.297616e-02,9.573670e-02&quot; ... #&gt; $ R0 : num 0.304 0.308 0.623 0.978 0.806 ... #&gt; $ R1 : num 0.411 0.376 0.356 0.3 0.336 ... #&gt; $ KING : num 0.0948 0.088 -0.0588 -0.2193 -0.147 ... #&gt; $ X2dsfs_loglike : num -436960 -438618 -430614 -275453 -390905 ... #&gt; $ X2dsfsf_niter : int 10 10 10 10 10 10 10 10 10 10 ... Relatedness was estimated on an average of 2.424729710^{5} sites and a mean coverage of 0.7979156. On average, relatedness is 0.0815924 with a range of 210^{-6}, 0.294369. We join together the relatedness estimates with the sample information, to know the identity of the dyads #rename &quot;ida&quot; and &quot;idb&quot; to &quot;RGSM_a&quot; and &quot;RGSM-b&quot; ngsRelate_results &lt;- rename(ngsRelate_results, &quot;RGSM_a&quot; = &quot;ida&quot;) ngsRelate_results &lt;- rename(ngsRelate_results, &quot;RGSM_b&quot; = &quot;idb&quot;) #create a new column that includes RGSM_dyad ngsRelate_results$RGSM_dyad &lt;- if_else(ngsRelate_results$RGSM_a &lt; ngsRelate_results$RGSM_b, paste(ngsRelate_results$RGSM_a, ngsRelate_results$RGSM_b, sep = &quot;-&quot;), paste(ngsRelate_results$RGSM_b, ngsRelate_results$RGSM_a, sep = &quot;-&quot;)) #first include ID of individual a ngsRelate_results_ID &lt;- left_join(ngsRelate_results, seqlib_overview[6:7], by = c(&quot;RGSM_a&quot; = &quot;RGSM&quot;)) #rename &quot;ID&quot; to &quot;ID_a&quot; ngsRelate_results_ID &lt;- rename(ngsRelate_results_ID, &quot;ID_a&quot; = &quot;ID&quot;) #now include ID of individual b ngsRelate_results_ID &lt;- left_join(ngsRelate_results_ID, seqlib_overview[6:7], by = c(&quot;RGSM_b&quot; = &quot;RGSM&quot;)) #rename &quot;ID&quot; to &quot;ID_b&quot; ngsRelate_results_ID &lt;- rename(ngsRelate_results_ID, &quot;ID_b&quot; = &quot;ID&quot;) #create a new column that includes the dyad ngsRelate_results_ID$dyad &lt;- if_else(ngsRelate_results_ID$ID_a &lt; ngsRelate_results_ID$ID_b, paste(ngsRelate_results_ID$ID_a, ngsRelate_results_ID$ID_b, sep = &quot;-&quot;), paste(ngsRelate_results_ID$ID_b, ngsRelate_results_ID$ID_a, sep = &quot;-&quot;)) #remove duplicates ##maybe not necessary anymore ngsRelate_results_ID &lt;- distinct(ngsRelate_results_ID) We also include the group information #first include group of individual a ngsRelate_results_ID_group &lt;- left_join(ngsRelate_results_ID, sampleID_group, by = c(&quot;ID_a&quot; = &quot;ID&quot;)) #rename &quot;Group_ID&quot; to &quot;a_Group&quot; ngsRelate_results_ID_group &lt;- rename(ngsRelate_results_ID_group, &quot;a_Group&quot; = &quot;Group_ID&quot;) #then include group of individual b ngsRelate_results_ID_group &lt;- left_join(ngsRelate_results_ID_group, sampleID_group, by = c(&quot;ID_b&quot; = &quot;ID&quot;)) #rename &quot;Group_ID&quot; to &quot;b_Group&quot; ngsRelate_results_ID_group &lt;- rename(ngsRelate_results_ID_group, &quot;b_Group&quot; = &quot;Group_ID&quot;) #which group IDs are there? sort(unique(ngsRelate_results_ID_group$a_Group)) #&gt; [1] &quot;5509&quot; &quot;5512&quot; &quot;5931-5938&quot; &quot;dump&quot; &quot;mpala&quot; #&gt; [6] &quot;mpala_chicks&quot; &quot;ROOP&quot; &quot;RRWB&quot; &quot;wing_tags&quot; &quot;wt025&quot; sort(unique(ngsRelate_results_ID_group$b_Group)) #&gt; [1] &quot;5509&quot; &quot;5512&quot; &quot;5931-5938&quot; &quot;dump&quot; &quot;mpala&quot; #&gt; [6] &quot;mpala_chicks&quot; &quot;ROOP&quot; &quot;RRWB&quot; &quot;wing_tags&quot; &quot;wt025&quot; #create new column that specifies if individuals are from same or different groups ngsRelate_results_ID_group &lt;- ngsRelate_results_ID_group %&gt;% mutate(dyad_group = case_when(ID_a == ID_b ~ &quot;identical&quot;, a_Group == b_Group ~ &quot;intragroup&quot;, a_Group != b_Group ~ &quot;intergroup&quot;)) unique(ngsRelate_results_ID_group$dyad_group) #&gt; [1] &quot;intergroup&quot; &quot;intragroup&quot; &quot;identical&quot; NA Lets have a closer look at the samples that were sequenced twice #find samples that were sequenced twice duplicates &lt;- filter(ngsRelate_results_ID_group, ID_a == ID_b) #average relatedness of these duplicted inidividuals mean(duplicates$rab) #&gt; [1] 0.1362405 #range range(duplicates$rab) #&gt; [1] 0.109323 0.156439 Create subset with at least 250k SNPs ngsRelate_results_ID_group_250k &lt;- filter(ngsRelate_results_ID_group, nSites &gt;= 250000) unique(ngsRelate_results_ID_group_250k$dyad_group) #&gt; [1] &quot;intragroup&quot; &quot;intergroup&quot; NA To get an overview of the distribution of relatedness coefficients, we plot pairwise relatedness for all dyads theme_set(theme_classic()) #plot relatedness rab (y-axis) for every dyad (x-axis), ordered from low to high relatedness and colored according to inter- or intragroup dyad ggplot(ngsRelate_results_ID_group, aes(x = reorder(dyad, rab), y = rab, color = dyad_group)) + geom_point(alpha = 0.1, aes(y = rab)) + #plot relatedness estimates as points geom_hline(yintercept = c(0.125, 0.25, 0.5), linetype = &quot;dashed&quot;) + #include horizontal line to show traditional kinship categories labs( x = &quot;Dyad&quot;, y = &quot;Relatedness (ngsRelate)&quot;) 4.3.2.2 lcmlkin lcmlkin_results &lt;- read.delim(&quot;vignettes/data/pipeline/lcmlkin/relatedness.isec.0002.exMito.thinned.lcmlkin.results&quot;, header = TRUE, as.is = TRUE) str(lcmlkin_results) #&gt; &#39;data.frame&#39;: 7021 obs. of 7 variables: #&gt; $ Ind1 : chr &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; ... #&gt; $ Ind2 : chr &quot;RGID1_S81&quot; &quot;RGID1_S18&quot; &quot;RGID1_S55&quot; &quot;RGID1_S4&quot; ... #&gt; $ k0_hat: num 0.775 0.776 0.88 0.856 0.866 0.856 0.863 0.865 0.749 0.859 ... #&gt; $ k1_hat: num 0.002 0.003 0.003 0.003 0.003 0.002 0.003 0.003 0.003 0.002 ... #&gt; $ k2_hat: num 0.223 0.221 0.118 0.141 0.132 0.142 0.134 0.132 0.248 0.139 ... #&gt; $ pi_HAT: num 0.224 0.222 0.119 0.143 0.133 0.143 0.136 0.134 0.25 0.14 ... #&gt; $ nbSNP : int 271505 241476 239421 263248 257387 276355 241041 257640 274309 270529 ... We join together the relatedness estimates with the sample information, to know the identity of the dyads #rename &quot;ida&quot; and &quot;idb&quot; to &quot;RGSM_a&quot; and &quot;RGSM-b&quot; lcmlkin_results &lt;- rename(lcmlkin_results, &quot;RGSM_a&quot; = &quot;Ind1&quot;) lcmlkin_results &lt;- rename(lcmlkin_results, &quot;RGSM_b&quot; = &quot;Ind2&quot;) #create a new column that includes RGSM_dyad lcmlkin_results$RGSM_dyad &lt;- if_else(lcmlkin_results$RGSM_a &lt; lcmlkin_results$RGSM_b, paste(lcmlkin_results$RGSM_a, lcmlkin_results$RGSM_b, sep = &quot;-&quot;), paste(lcmlkin_results$RGSM_b, lcmlkin_results$RGSM_a, sep = &quot;-&quot;)) #first include ID of individual a lcmlkin_results_ID &lt;- left_join(lcmlkin_results, seqlib_overview[6:7], by = c(&quot;RGSM_a&quot; = &quot;RGSM&quot;)) #rename &quot;ID&quot; to &quot;ID_a&quot; lcmlkin_results_ID &lt;- rename(lcmlkin_results_ID, &quot;ID_a&quot; = &quot;ID&quot;) #now include ID of individual b lcmlkin_results_ID &lt;- left_join(lcmlkin_results_ID, seqlib_overview[6:7], by = c(&quot;RGSM_b&quot; = &quot;RGSM&quot;)) #rename &quot;ID&quot; to &quot;ID_b&quot; lcmlkin_results_ID &lt;- rename(lcmlkin_results_ID, &quot;ID_b&quot; = &quot;ID&quot;) #create a new column that includes the dyad lcmlkin_results_ID$dyad &lt;- if_else(lcmlkin_results_ID$ID_a &lt; lcmlkin_results_ID$ID_b, paste(lcmlkin_results_ID$ID_a, lcmlkin_results_ID$ID_b, sep = &quot;-&quot;), paste(lcmlkin_results_ID$ID_b, lcmlkin_results_ID$ID_a, sep = &quot;-&quot;)) #remove duplicates ##maybe not necessary anymore lcmlkin_results_ID &lt;- distinct(lcmlkin_results_ID) We also include the group information #first include group of individual a lcmlkin_results_ID_group &lt;- left_join(lcmlkin_results_ID, sampleID_group, by = c(&quot;ID_a&quot; = &quot;ID&quot;)) #rename &quot;Group_ID&quot; to &quot;a_Group&quot; lcmlkin_results_ID_group &lt;- rename(lcmlkin_results_ID_group, &quot;a_Group&quot; = &quot;Group_ID&quot;) #then include group of individual b lcmlkin_results_ID_group &lt;- left_join(lcmlkin_results_ID_group, sampleID_group, by = c(&quot;ID_b&quot; = &quot;ID&quot;)) #rename &quot;Group_ID&quot; to &quot;b_Group&quot; lcmlkin_results_ID_group &lt;- rename(lcmlkin_results_ID_group, &quot;b_Group&quot; = &quot;Group_ID&quot;) #create new column that specifies if individuals are from same or different groups lcmlkin_results_ID_group &lt;- lcmlkin_results_ID_group %&gt;% mutate(dyad_group = if_else(a_Group == b_Group, &quot;intra&quot;, &quot;inter&quot;)) str(lcmlkin_results_ID_group) #&gt; &#39;data.frame&#39;: 7021 obs. of 14 variables: #&gt; $ RGSM_a : chr &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; &quot;RGID1_S35&quot; ... #&gt; $ RGSM_b : chr &quot;RGID1_S81&quot; &quot;RGID1_S18&quot; &quot;RGID1_S55&quot; &quot;RGID1_S4&quot; ... #&gt; $ k0_hat : num 0.775 0.776 0.88 0.856 0.866 0.856 0.863 0.865 0.749 0.859 ... #&gt; $ k1_hat : num 0.002 0.003 0.003 0.003 0.003 0.002 0.003 0.003 0.003 0.002 ... #&gt; $ k2_hat : num 0.223 0.221 0.118 0.141 0.132 0.142 0.134 0.132 0.248 0.139 ... #&gt; $ pi_HAT : num 0.224 0.222 0.119 0.143 0.133 0.143 0.136 0.134 0.25 0.14 ... #&gt; $ nbSNP : int 271505 241476 239421 263248 257387 276355 241041 257640 274309 270529 ... #&gt; $ RGSM_dyad : chr &quot;RGID1_S35-RGID1_S81&quot; &quot;RGID1_S18-RGID1_S35&quot; &quot;RGID1_S35-RGID1_S55&quot; &quot;RGID1_S35-RGID1_S4&quot; ... #&gt; $ ID_a : chr &quot;W1673&quot; &quot;W1673&quot; &quot;W1673&quot; &quot;W1673&quot; ... #&gt; $ ID_b : chr &quot;WT00203&quot; &quot;W1376&quot; &quot;A1316&quot; &quot;W1502&quot; ... #&gt; $ dyad : chr &quot;W1673-WT00203&quot; &quot;W1376-W1673&quot; &quot;A1316-W1673&quot; &quot;W1502-W1673&quot; ... #&gt; $ a_Group : chr &quot;wt025&quot; &quot;wt025&quot; &quot;wt025&quot; &quot;wt025&quot; ... #&gt; $ b_Group : chr &quot;mpala_chicks&quot; &quot;dump&quot; &quot;wing_tags&quot; &quot;RRWB&quot; ... #&gt; $ dyad_group: chr &quot;inter&quot; &quot;inter&quot; &quot;inter&quot; &quot;inter&quot; ... Lets have a closer look at the samples that were sequenced twice #find samples that were sequenced twice duplicates_lcmlkin &lt;- filter(lcmlkin_results_ID, ID_a == ID_b) #average relatedness of these duplicted inidividuals mean(duplicates_lcmlkin$pi_HAT) #&gt; [1] 0.296087 #range range(duplicates_lcmlkin$pi_HAT) #&gt; [1] 0.230 0.328 Create subset with at least 300k SNPs lcmlkin_results_ID_group_300k &lt;- filter(lcmlkin_results_ID_group, nbSNP &gt;= 300000) theme_set(theme_classic()) #plot relatedness pi_HAT (y-axis) for every dyad (x-axis), ordered from low to high relatedness and colored according to inter- or intragroup dyad ggplot(lcmlkin_results_ID_group_300k, aes(x = reorder(dyad, pi_HAT), y = pi_HAT, color = dyad_group)) + geom_point(alpha = 0.1, aes(y = pi_HAT)) + #plot relatedness estimates as points geom_hline(yintercept = c(0.125, 0.25, 0.5), linetype = &quot;dashed&quot;) + #include horizontal line to show traditional kinship categories labs( x = &quot;Dyad&quot;, y = &quot;Relatedness (lcmlkin)&quot;) 4.3.2.3 READ This is an assessment of the READ results produced by the Nextflow pipleine created by Ben Hume/SeqAna. The data is saved in the folder pipeline in read as meansP0_AncientDNA_normalized. The preprocessed data (categorizes unrelated, first- and second-order related) is sotred as READ_results. READ_rawresults &lt;- read.delim(&quot;vignettes/data/pipeline/read/meansP0_AncientDNA_normalized&quot;, header = TRUE, sep = &quot; &quot;, as.is = TRUE) str(READ_rawresults) #&gt; &#39;data.frame&#39;: 7021 obs. of 5 variables: #&gt; $ PairIndividuals : chr &quot;RGID1_S10RGID1_S11&quot; &quot;RGID1_S10RGID1_S19&quot; &quot;RGID1_S10RGID1_S23&quot; &quot;RGID1_S10RGID1_S26&quot; ... #&gt; $ Normalized2AlleleDifference: num 0.975 0.922 0.962 0.994 0.931 ... #&gt; $ StandardError : num 0.00922 0.01094 0.012 0.01045 0.00995 ... #&gt; $ NonNormalizedP0 : num 0.338 0.32 0.334 0.345 0.323 ... #&gt; $ NonNormalizedStandardError : num 0.0032 0.00379 0.00416 0.00363 0.00345 ... READ_kinresults &lt;- read.delim(&quot;vignettes/data/pipeline/read/READ_results&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = TRUE) str(READ_kinresults) #&gt; &#39;data.frame&#39;: 7021 obs. of 4 variables: #&gt; $ PairIndividuals: chr &quot;RGID1_S10RGID1_S11&quot; &quot;RGID1_S10RGID1_S19&quot; &quot;RGID1_S10RGID1_S23&quot; &quot;RGID1_S10RGID1_S26&quot; ... #&gt; $ Relationship : chr &quot;Unrelated&quot; &quot;Unrelated&quot; &quot;Unrelated&quot; &quot;Unrelated&quot; ... #&gt; $ Z_upper : num NA NA NA NA NA NA NA NA NA NA ... #&gt; $ Z_lower : num -7.47 -1.43 -4.65 -8.37 -2.51 ... Merge these two result files READ_results &lt;- left_join(READ_rawresults, READ_kinresults, by = &quot;PairIndividuals&quot;) str(READ_results) #&gt; &#39;data.frame&#39;: 7021 obs. of 8 variables: #&gt; $ PairIndividuals : chr &quot;RGID1_S10RGID1_S11&quot; &quot;RGID1_S10RGID1_S19&quot; &quot;RGID1_S10RGID1_S23&quot; &quot;RGID1_S10RGID1_S26&quot; ... #&gt; $ Normalized2AlleleDifference: num 0.975 0.922 0.962 0.994 0.931 ... #&gt; $ StandardError : num 0.00922 0.01094 0.012 0.01045 0.00995 ... #&gt; $ NonNormalizedP0 : num 0.338 0.32 0.334 0.345 0.323 ... #&gt; $ NonNormalizedStandardError : num 0.0032 0.00379 0.00416 0.00363 0.00345 ... #&gt; $ Relationship : chr &quot;Unrelated&quot; &quot;Unrelated&quot; &quot;Unrelated&quot; &quot;Unrelated&quot; ... #&gt; $ Z_upper : num NA NA NA NA NA NA NA NA NA NA ... #&gt; $ Z_lower : num -7.47 -1.43 -4.65 -8.37 -2.51 ... Now we need to split the PairIndividuals into individual 1 and 2, identify these individuals and then create the dyads corresponding to the previous results. #Need to split PairIndividuals into 2 new columns READ_results$RGSM_a &lt;- gsub(&quot;(RGID[[:alnum:]]{1}_S[[:alnum:]]{1,2})(RGID[[:alnum:]]{1}_S[[:alnum:]]{1,2})&quot;, &quot;\\\\1&quot;, READ_results$PairIndividuals) READ_results$RGSM_b &lt;- gsub(&quot;(RGID[[:alnum:]]{1}_S[[:alnum:]]{1,2})(RGID[[:alnum:]]{1}_S[[:alnum:]]{1,2})&quot;, &quot;\\\\2&quot;, READ_results$PairIndividuals) #create a new column that includes RGSM_dyad READ_results$RGSM_dyad &lt;- if_else(READ_results$RGSM_a &lt; READ_results$RGSM_b, paste(READ_results$RGSM_a, READ_results$RGSM_b, sep = &quot;-&quot;), paste(READ_results$RGSM_b, READ_results$RGSM_a, sep = &quot;-&quot;)) str(READ_results) #&gt; &#39;data.frame&#39;: 7021 obs. of 11 variables: #&gt; $ PairIndividuals : chr &quot;RGID1_S10RGID1_S11&quot; &quot;RGID1_S10RGID1_S19&quot; &quot;RGID1_S10RGID1_S23&quot; &quot;RGID1_S10RGID1_S26&quot; ... #&gt; $ Normalized2AlleleDifference: num 0.975 0.922 0.962 0.994 0.931 ... #&gt; $ StandardError : num 0.00922 0.01094 0.012 0.01045 0.00995 ... #&gt; $ NonNormalizedP0 : num 0.338 0.32 0.334 0.345 0.323 ... #&gt; $ NonNormalizedStandardError : num 0.0032 0.00379 0.00416 0.00363 0.00345 ... #&gt; $ Relationship : chr &quot;Unrelated&quot; &quot;Unrelated&quot; &quot;Unrelated&quot; &quot;Unrelated&quot; ... #&gt; $ Z_upper : num NA NA NA NA NA NA NA NA NA NA ... #&gt; $ Z_lower : num -7.47 -1.43 -4.65 -8.37 -2.51 ... #&gt; $ RGSM_a : chr &quot;RGID1_S10&quot; &quot;RGID1_S10&quot; &quot;RGID1_S10&quot; &quot;RGID1_S10&quot; ... #&gt; $ RGSM_b : chr &quot;RGID1_S11&quot; &quot;RGID1_S19&quot; &quot;RGID1_S23&quot; &quot;RGID1_S26&quot; ... #&gt; $ RGSM_dyad : chr &quot;RGID1_S10-RGID1_S11&quot; &quot;RGID1_S10-RGID1_S19&quot; &quot;RGID1_S10-RGID1_S23&quot; &quot;RGID1_S10-RGID1_S26&quot; ... We join together the relatedness estimates with the sample information, to know the identity of the dyads #first include ID of individual a READ_results_ID &lt;- left_join(READ_results, seqlib_overview[6:7], by = c(&quot;RGSM_a&quot; = &quot;RGSM&quot;)) #rename &quot;ID&quot; to &quot;ID_a&quot; READ_results_ID &lt;- rename(READ_results_ID, &quot;ID_a&quot; = &quot;ID&quot;) #now include ID of individual b READ_results_ID &lt;- left_join(READ_results_ID, seqlib_overview[6:7], by = c(&quot;RGSM_b&quot; = &quot;RGSM&quot;)) #rename &quot;ID&quot; to &quot;ID_b&quot; READ_results_ID &lt;- rename(READ_results_ID, &quot;ID_b&quot; = &quot;ID&quot;) #create a new column that includes the dyad READ_results_ID$dyad &lt;- if_else(READ_results_ID$ID_a &lt; READ_results_ID$ID_b, paste(READ_results_ID$ID_a, READ_results_ID$ID_b, sep = &quot;-&quot;), paste(READ_results_ID$ID_b, READ_results_ID$ID_a, sep = &quot;-&quot;)) #remove duplicates ##maybe not necessary anymore READ_results_ID &lt;- distinct(READ_results_ID) Lets have a closer look at the samples that were sequenced twice #find samples that were sequenced twice duplicates &lt;- filter(READ_results_ID, ID_a == ID_b) #average relatedness of these duplicted inidividuals mean(duplicates$NonNormalizedP0) #&gt; [1] 0.315183 #range range(duplicates$NonNormalizedP0) #&gt; [1] 0.2880766 0.3502312 theme_set(theme_classic()) #plot relatedness P0 (y-axis) for every dyad (x-axis), ordered from low to high relatedness and colored according to inter- or intragroup dyad ggplot(READ_results, aes(x = reorder(PairIndividuals, NonNormalizedP0), y = NonNormalizedP0, color = Relationship)) + geom_point(alpha = 0.1, aes(y = NonNormalizedP0)) + #plot relatedness estimates as points labs( x = &quot;Dyad&quot;, y = &quot;Relatedness (READ)&quot;) 4.3.2.4 Combined relatedness results merge ngsrelate and lcmlkin relate_results &lt;- full_join(ngsRelate_results_ID_group, lcmlkin_results_ID_group, by = &quot;RGSM_dyad&quot;) relate_results &lt;- full_join(relate_results, READ_results_ID, by = &quot;RGSM_dyad&quot;) plot theme_set(theme_classic()) #plot relatedness pi_HAT and rab (y-axis) for every dyad (x-axis), ordered from low to high relatedness and colored according to inter- or intragroup dyad ggplot(filter(relate_results, coverage &gt; 0.95), aes(x = reorder(dyad, pi_HAT))) + geom_point(alpha = 0.1, aes(y = pi_HAT), color = &quot;blue&quot;) + #plot lcmlkin relatedness estimates as points geom_point(alpha = 0.1, aes(y = NonNormalizedP0), color = &quot;red&quot;) + #plot READ estimate geom_point(alpha = 0.1, aes(y = rab), color = &quot;black&quot;) + # plot ngsRelate estimates scale_y_continuous( name = &quot;relatedness (lcmlkin)&quot;, #features of first axis sec.axis = sec_axis(~., name = &quot;P0&quot;) #features of second axis ) + ggtitle(&quot;Comparison of relatedness estimators (&gt;0.95X)&quot;) Compare correlation among the three estimators ggplot(relate_results, aes(x = rab, y = pi_HAT, color = coverage, size = nSites, shape = dyad_group.x)) + scale_colour_viridis_c() + geom_point(alpha = 0.2) #&gt; Warning: Removed 351 rows containing missing values (geom_point). ggplot(relate_results, aes(x = rab, y = NonNormalizedP0, color = coverage, size = nSites, shape = dyad_group.x)) + scale_colour_viridis_c() + geom_point(alpha = 0.2) #&gt; Warning: Removed 351 rows containing missing values (geom_point). ggplot(relate_results, aes(x = pi_HAT, y = NonNormalizedP0, color = coverage, size = nSites, shape = dyad_group.x)) + scale_colour_viridis_c() + geom_point(alpha = 0.2) #&gt; Warning: Removed 351 rows containing missing values (geom_point). For comparison of relatedness estimators check Yaka et al. 2021 Curr Biol. "],["analysis.html", "5 Analysis 5.1 Setup 5.2 Data overview 5.3 Analysis 2", " 5 Analysis 5.1 Setup library(tidyverse) #&gt; -- Attaching packages ------------------------------------------------------------------------------------------------------------------ tidyverse 1.3.0 -- #&gt; v ggplot2 3.3.2 v purrr 0.3.4 #&gt; v tibble 3.0.3 v dplyr 1.0.2 #&gt; v tidyr 1.1.2 v stringr 1.4.0 #&gt; v readr 1.3.1 v forcats 0.5.0 #&gt; -- Conflicts --------------------------------------------------------------------------------------------------------------------- tidyverse_conflicts() -- #&gt; x dplyr::filter() masks stats::filter() #&gt; x dplyr::lag() masks stats::lag() library(ggplot2) library(ggthemes) library(ggforce) library(ggridges) library(ggsci) library(wesanderson) library(gghighlight) 5.2 Data overview An overview of the samples as of 26th April 2021 is stored in Guineafowl-lcWGS_DataOverview_20210426.csv. This is needed to later assign the relatedness estimates to specific individuals sample_overview &lt;- read.csv(&quot;vignettes/data/Guineafowl-lcWGS_DataOverview_20210426.csv&quot;, header = TRUE, sep = &quot;;&quot;, as.is = TRUE) str(sample_overview) #&gt; &#39;data.frame&#39;: 119 obs. of 17 variables: #&gt; $ individual : chr &quot;W1398&quot; &quot;W1429&quot; &quot;W1429&quot; &quot;W1502&quot; ... #&gt; $ library : chr &quot;L16926&quot; &quot;L16927&quot; &quot;L16927&quot; &quot;L16928&quot; ... #&gt; $ run : chr &quot;S2&quot; &quot;S1&quot; &quot;S3&quot; &quot;S4&quot; ... #&gt; $ original.o..resequenced.r. : chr &quot;o&quot; &quot;r&quot; &quot;o&quot; &quot;o&quot; ... #&gt; $ readGroupID : int 4 5 4 4 4 5 4 4 4 4 ... #&gt; $ total.reads : int 6720264 21332072 6069840 13390576 12081324 11995744 5684766 7759668 12174890 11373232 ... #&gt; $ trim.input.reads : int 3360132 10666036 3034920 6695288 6040662 5997872 2842383 3879834 6087445 5686616 ... #&gt; $ trim.reads.survived.both : int 2544284 9427764 2360036 5279275 4602830 5309238 2225803 2852960 4754568 4400910 ... #&gt; $ trim.reads.dropped.... : num 0.24 0.12 0.22 0.21 0.24 0.11 0.22 0.26 0.22 0.23 ... #&gt; $ mapped.reads : int 4987783 18494700 4631339 10376967 9021788 10412331 4367512 5598370 9342782 8636957 ... #&gt; $ mapped.reads.... : num 98 98.1 98.1 98.3 98 ... #&gt; $ coverage.mean : num 0.56 2.06 0.52 1.14 0.97 1.14 0.48 0.63 1.05 0.98 ... #&gt; $ coverage.st.dev. : num 2.48 4.96 2.58 2.8 3.81 3.56 2.18 2.43 2.58 3.13 ... #&gt; $ Duplicates.... : num 5.07 8.13 4.92 5.2 5.09 9.35 5.56 4.54 4.59 4.84 ... #&gt; $ Lib.complexity.total.reads : int 2250000 8750000 2250000 5000000 4250000 4750000 2000000 2750000 4500000 4250000 ... #&gt; $ Lib.complexity.distinct.reads: int 2224740 8608220 2221360 4963340 4181270 4688400 1979850 2722780 4466910 4203570 ... #&gt; $ number.of.snps : logi NA NA NA NA NA NA ... 5.3 Analysis 2 "],["references-and-session-info.html", "6 References and Session Info 6.1 Session Info 6.2 References", " 6 References and Session Info 6.1 Session Info sessionInfo() #&gt; R version 3.6.3 (2020-02-29) #&gt; Platform: x86_64-w64-mingw32/x64 (64-bit) #&gt; Running under: Windows 10 x64 (build 18363) #&gt; #&gt; Matrix products: default #&gt; #&gt; locale: #&gt; [1] LC_COLLATE=German_Germany.1252 LC_CTYPE=German_Germany.1252 #&gt; [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C #&gt; [5] LC_TIME=German_Germany.1252 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] bookdown_0.21 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] compiler_3.6.3 magrittr_1.5 htmltools_0.5.0 tools_3.6.3 #&gt; [5] yaml_2.2.1 stringi_1.4.6 rmarkdown_2.6 knitr_1.30 #&gt; [9] stringr_1.4.0 digest_0.6.25 xfun_0.17 rlang_0.4.7 #&gt; [13] evaluate_0.14 6.2 References "]]
